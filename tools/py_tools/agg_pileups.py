#!/usr/bin/env python

import argparse
import sys
import gzip
import json
import pysam
from collections import defaultdict
from statistics import mean, median

app_desc = "Aggregate depth information individual depth files generated by SAMtools mpileup."
argparser = argparse.ArgumentParser(description=app_desc)

in_help = """ Input file which lists paths to depth files.
    One depth file per sample. One file per line. """
argparser.add_argument('-i', '--in', metavar='file', dest='in_files_list', required=True,
                       help=in_help)

out_help = """ Output file of depth information compressed with bgzip.
    In addition to this file, the tabix index will be produced. """
argparser.add_argument('-o', '--out', metavar='file', dest='out_file_name', required=True,
                       help=out_help)

DEPTH_BREAKS = [1, 5, 10, 15, 20, 25, 30, 50, 100]


# TODO: test against numpy.histogram
def count_depths(depths):
    counts = [0] * len(DEPTH_BREAKS)
    for depth in depths:
        for idx, break_val in enumerate(DEPTH_BREAKS):
            if depth >= break_val:
                counts[idx] += 1
    return(counts)


if __name__ == '__main__':
    args = argparser.parse_args()

    # Process list of depth file paths
    input_paths = []
    with open(args.in_files_list, 'r') as ifile:
        for line in ifile:
            line = line.strip()
            if line:
                input_paths.append(line)

    # If input paths is empty, we're done
    if not input_paths:
        print("Input paths empty", file=sys.stderr)
        sys.exit()

    # Get chromosome value from first file to ensure all subsequent reads are of same chromosome.
    with gzip.open(input_paths[0], 'rt') as first_file:
        line = first_file.readline()
        if line:
            chrom, pos, dp = line.rstrip().split()
            chromosome = chrom
        else:
            print("First input file empty", file=sys.stderr)
            sys.exit(1)
    # Create non-chr prefixed chromosome identifier and validate chromosome string.
    chromosome_id = chromosome.replace('chr', '', 1)

    ####################
    # Read input files #
    ####################
    # Go through each file and collect depths for each position
    positions = defaultdict(list)
    for input_path in input_paths:
        with gzip.open(input_path, 'rt') as infile:
            count = 0
            for line in infile:
                chrom, pos, dp = line.rstrip().split()
                if chrom != chromosome:
                    raise Exception('Multiple chromosomes detected in input. Only one is allowed.')
                count = count+1
                positions[int(pos)].append(int(dp))

    #####################
    # Write Output File #
    #####################
    with pysam.BGZFile(args.out_file_name, 'w') as ofile:
        # Process depth data in ascending position order
        n_indv = len(input_paths)
        asc_keys = sorted(positions)
        for pkey in asc_keys:
            depth_counts = count_depths(positions[pkey])

            summary = {}
            summary["chrom"] = chromosome_id
            summary["start"] = pkey
            summary["end"] = pkey
            summary["mean"] = mean(positions[pkey])
            summary["median"] = median(positions[pkey])

            # Calculate proportion of individuals counted in each bin for current position
            for br, depth_count in zip(DEPTH_BREAKS, depth_counts):
                proportion = depth_count / n_indv
                summary[br] = proportion

            agg_row = f'{chromosome_id}\t{pkey}\t{pkey}\t{json.dumps(summary)}'
    print("Done")
