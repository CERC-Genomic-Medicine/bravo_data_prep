params {
  // INFO fields to be carried over (must be type double)
  qc_metrics = "ABE ABZ BQZ CYZ FIBC_I FIBC_P HWE_SLP_I HWE_SLP_P IOR NM0 NM1 NMZ STZ SVM"

  // Columns and INFO tags to annotate from sites bcfs into histogram bcfs
  anno_fields="QUAL,FILTER,ABE,ABZ,BQZ,CYZ,FIBC_I,FIBC_P,HWE_SLP_I,HWE_SLP_P,IOR,NM0,NM1,NMZ,STZ,SVM"

  // Use NO_FILE to indicate the optional samples list will be generated from samples in vcf.
  samples_path    = "NO_FILE"

  // BCFs with DP & GQ fields (full bcfs)
  // "/mnt/vcfs/freeze10/genotypes/merged/chr11/*.{bcf,bcf.csi}"
  bcfs_full       = "data/bcfs/full/*.{bcf,bcf.csi}"

  // BCFS with qc_metrics (sites bcfs)
  // "/mnt/vcfs/freeze10/subsets/topmed/sites/freeze10.topmed.chr11.filtered.sites.bcf"
  bcfs_sites      = "data/bcfs/sites/freeze10.topmed.*.filtered.sites.{bcf,bcf.csi}"
  bcfs_sites_dir  = "data/bcfs/sites"

  // Path glob to get both the bcf and the index files as pairs
  bcfs_glob       = "data/bcfs/*.{bcf,bcf.csi}"

  vep {
    static_flags = ["--sift b",  "--polyphen b", "--ccds",       "--uniprot",    "--hgvs", 
                    "--symbol",  "--numbers",    "--domains",    "--regulatory", "--canonical",
                    "--protein", "--biotype",    "--af",         "--af_1kg",     "--af_esp",
                    "--af_gnomad", "--pubmed",   "--shift_hgvs 0", "--allele_number", 
                    "--buffer_size 50000", "--format vcf", "--cache", "--offline", "--vcf",
                    " --compress_output bgzip", "--no_stats"
                   ].join(" ")

    loftee_path              = "/apps/loftee"
    loftee_human_ancestor_fa = "/apps/loftee_data/human_ancestor.fa.gz"
    loftee_conservation_file = "/apps/loftee_data/loftee.sql"
    loftee_gerp_bigwig       = "/apps/loftee_data/gerp_conservation_scores.homo_sapiens.GRCh38.bw"
    ref_fasta                = "/apps/reference/hs38DH.fa"
    cache                    = "/apps/vep_cache"
  }

  cadd {
    script = "/apps/data_prep/tools/py_tools/add_cadd_scores.py"
    tsv_path = "/apps/reference/cadd/whole_genome_SNVs.tsv.gz"
  }

  percentiles {
     qc_metrics = ["ABE", "ABZ", "BQZ", "CYZ", "FIBC_I", "FIBC_P", "HWE_SLP_I",
       "HWE_SLP_P", "IOR", "NM0", "NM1", "NMZ", "STZ", "SVM", "QUAL"]
  }
}

executor {
  $slurm {
    queueSize = 1000
    cpus = 1
    memory = "6GB"
  }
  $local {
    // Number of cores to use for processes.
    cpus = 3 
  }
}

// To run on cluster use: nextflow run PrepareVCF.nf -profile slurm
profiles {
  standard {
    process.executor = 'local'
  }

  slurm {
    process.executor = 'slurm'
    process.queue = "bravo"
    process.time = "14d"
    process.module = ['vep', 'htslib','samtools', 'bam_util', 'data_prep', 'python3', 'bcftools']
  }
}
